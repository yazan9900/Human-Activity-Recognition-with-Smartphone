# Human-Activity-Recognition-with-Smartphone
[![MIT License](https://img.shields.io/apm/l/atomic-design-ui.svg?)](https://github.com/TRoboto/datacamp-downloader/blob/master/LICENSE)

The Human Activity Recognition database was built from the recordings of 30 study participants performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. The objective is to classify activities into one of the six activities performed.

Activites studied in this dataset are:
  - STANDING
  - SITTING
  - LAYING
  - WALKING
  - WALKING_DOWNSTAIRS
  - WALKING_UPSTAIRS

The `Human_Activity_Recognition_with_Smartphones.ipynb` notebook icludes my work on this dataset:
  - Analysis
  - Plotting
  - Classifying
    - SGDClassifier
    - Linear SVC
    - RBF SVC
 
Best reults delivered by the RBF SVC model and this the confusion matrix result:

![RBF SVC predictions Confusion Matrix](/Images/RBF-SVC-predictions-Confusion-Matrix.png)
